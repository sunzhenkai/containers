version: "2"
networks:
  default:
    driver: bridge
    ipam:
      config:
        - subnet: "172.50.0.0/24"
          gateway: "172.50.0.1"
volumes:
  data:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data
  kafka:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/kafka
  mariadb:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/mariadb
  clickhouse:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/clickhouse
  consul:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/consul
  zookeeper:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/consul
  postgresql:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/postgresql
  redis:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/redis
  mongodb:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/mongodb
  grafana:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/grafana
  harbor-core:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/harbor-core
  dolphinscheduler-worker-data:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/dolphinscheduler-worker-data
  dolphinscheduler-logs:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/dolphinscheduler-logs
  dolphinscheduler-shared-local:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/dolphinscheduler-shared-local
  dolphinscheduler-resource-local:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/dolphinscheduler-resource-local 
services:
  hadoop_namenode:
    image: apache/hadoop:3
    hostname: namenode
    command: ["hdfs", "namenode"]
    restart: always
    ports:
      - 9870:9870
    env_file:
      - ./config/hadoop/config
    volumes:
      - data:/data
      # - ./hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    environment:
      ENSURE_NAMENODE_DIR: "/data/dfs/name"
    networks:
      - default
  hadoop_datanode:
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    restart: always
    env_file:
      - ./config/hadoop/config
    networks:
      - default
    volumes:
      - data:/data
  hadoop_resourcemanager:
    image: apache/hadoop:3
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    restart: always
    ports:
      - 8088:8088
    env_file:
      - ./config/hadoop/config
    networks:
      - default
    volumes:
      - data:/data
  hadoop_nodemanager:
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    restart: always
    env_file:
      - ./config/hadoop/config
    networks:
      - default
    volumes:
      - data:/data
  development_node:
    image: sunzhenkai/development:0.0.3
    command: ["/sbin/init"]
    restart: always
    privileged: true
    networks:
      - default
    ports:
      - 2025:22
      - 8285:8085
    volumes:
      - data:/data
  spark:
    image: docker.io/bitnami/spark:3.4
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - 8286:8080
      - 8277:7077
    networks:
      - default
  spark-worker:
    image: docker.io/bitnami/spark:3.4
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=60G
      - SPARK_WORKER_CORES=30
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    networks:
      - default
    deploy:
      mode: replicated
      replicas: 2
  zeeplin:
    image: apache/zeppelin:0.10.1
    environment:
      - ZEPPELIN_LOG_DIR='/data/zeeplin/logs'
      - ZEPPELIN_NOTEBOOK_DIR='/data/zeeplin/notebook'
    ports:
      - 8280:8080
    networks:
      - default
    volumes:
      - data:/data
  flink-jobmanager:
    image: docker.io/bitnami/flink:1
    ports:
      - 8223:6123
      - 8220:8081
    environment:
      - FLINK_MODE=jobmanager
      - FLINK_CFG_REST_BIND__ADDRESS=0.0.0.0
    networks:
      - default
  flink-taskmanager:
    image: docker.io/bitnami/flink:1
    ports:
      - 8221:6121
      - 8222:6122
    environment:
      - FLINK_MODE=taskmanager
      - FLINK_JOB_MANAGER_RPC_ADDRESS=jobmanager
    networks:
      - default
    deploy:
      mode: replicated
      replicas: 2
  kafka:
    image: docker.io/bitnami/kafka:3.5
    ports:
      - 8292:9092
    volumes:
      - "kafka:/bitnami"
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    networks:
      - default
  consul:
    image: docker.io/bitnami/consul:1
    volumes:
      - consul:/bitnami/consul
    ports:
      - '8200:8300'
      - '8201:8301'
      - '8201:8301/udp'
      - '8250:8500'
      - '8260:8600'
      - '8260:8600/udp'
    networks:
      - default
  clickhouse:
    image: docker.io/bitnami/clickhouse:23
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - '8233:8123'
    volumes:
      - clickhouse:/bitnami/clickhouse
    networks:
      - default
  postgresql:
    image: docker.io/bitnami/postgresql:15
    volumes:
      - 'postgresql:/bitnami/postgresql'
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - '5432:5432'
    healthcheck:
      test: ["CMD", "bash", "-c", "cat < /dev/null > /dev/tcp/127.0.0.1/5432"]
      interval: 5s
      timeout: 60s
      retries: 120
    networks:
      - default
  redis:
    image: docker.io/bitnami/redis:7.0
    volumes:
      - 'redis:/bitnami'
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - '6379:6379'
    networks:
      - default
  airflow-scheduler:
    image: docker.io/bitnami/airflow-scheduler:2
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    networks:
      - default
  airflow-worker:
    image: docker.io/bitnami/airflow-worker:2
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    networks:
      - default
  airflow:
    image: docker.io/bitnami/airflow:2
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
    ports:
      - '8208:8080'
    networks:
      - default
  prometheus:
    image: docker.io/bitnami/prometheus:2
    ports:
      - '8290:9090'
    networks:
      - default
  mongodb:
    image: docker.io/bitnami/mongodb:6.0
    ports:
      - "27017:27017"
    volumes:
      - 'mongodb:/bitnami/mongodb'
    networks:
      - default
  mariadb:
    image: docker.io/bitnami/mariadb:11.0
    ports:
      - '3306:3306'
    volumes:
      - 'mariadb:/bitnami/mariadb'
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    healthcheck:
      test: ['CMD', '/opt/bitnami/scripts/mariadb/healthcheck.sh']
      interval: 15s
      timeout: 5s
      retries: 6
    networks:
      - default
  phpmyadmin:
    image: docker.io/bitnami/phpmyadmin:5
    ports:
      - '8283:8080'
      - '8243:8443'
    depends_on:
      - mariadb
    networks:
      - default
  grafana:
    image: docker.io/bitnami/grafana:10
    ports:
      - '3000:3000'
    environment:
      - 'GF_SECURITY_ADMIN_PASSWORD=bitnami'
    volumes:
      - grafana:/opt/bitnami/grafana/data
    networks:
      - default
  harbor-core:
    image: docker.io/bitnami/harbor-core:2
    ports:
      - 8208:8080
    environment:
      - LOG_LEVEL=info
      - CONFIG_PATH=/etc/core/app.conf
      - CORE_SECRET=not-a-secure-core-secret
      - JOBSERVICE_SECRET=not-a-secure-jobservice-secret
    volumes:
      - ./config/habor-core/app.conf:/etc/core/app.conf:ro
      - ./config/habor-core/private_key.pem:/etc/core/private_key.pem:ro
      - harbor-core:/data
    networks:
      - default
  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    ports:
      - '2181:2181'
    volumes:
      - 'zookeeper:/bitnami/zookeeper'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - default
    healthcheck:
      test: ["CMD", "bash", "-c", "cat < /dev/null > /dev/tcp/127.0.0.1/2181"]
      interval: 5s
      timeout: 60s
      retries: 120
      
  # dolphinscheduler
  dolphinscheduler-schema-initializer:
    image: ghcr.io/apache/dolphinscheduler/dolphinscheduler-tools:latest
    profiles: ["schema"]
    command: [ tools/bin/upgrade-schema.sh ]
    depends_on:
      postgresql:
        condition: service_healthy
    volumes:
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
      - dolphinscheduler-shared-local:/opt/soft
      - dolphinscheduler-resource-local:/dolphinscheduler
    networks:
      - default
  dolphinscheduler-api:
    image: ghcr.io/apache/dolphinscheduler/dolphinscheduler-api:latest
    ports:
      - "12345:12345"
      - "25333:25333"
    profiles: ["all"]
    healthcheck:
      test: [ "CMD", "curl", "http://localhost:12345/dolphinscheduler/actuator/health" ]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
      - dolphinscheduler-shared-local:/opt/soft
      - dolphinscheduler-resource-local:/dolphinscheduler
    networks:
      - default
  dolphinscheduler-alert:
    image: ghcr.io/apache/dolphinscheduler/dolphinscheduler-alert-server:latest
    profiles: ["all"]
    healthcheck:
      test: [ "CMD", "curl", "http://localhost:50053/actuator/health" ]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
    networks:
      - default
  dolphinscheduler-master:
    image: ghcr.io/apache/dolphinscheduler/dolphinscheduler-master:latest
    profiles: ["all"]
    healthcheck:
      test: [ "CMD", "curl", "http://localhost:5679/actuator/health" ]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
      - dolphinscheduler-shared-local:/opt/soft
    networks:
      - default
  dolphinscheduler-worker:
    image: ghcr.io/apache/dolphinscheduler/dolphinscheduler-worker:latest
    profiles: ["all"]
    healthcheck:
      test: [ "CMD", "curl", "http://localhost:1235/actuator/health" ]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
      - dolphinscheduler-worker-data:/tmp/dolphinscheduler
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
      - dolphinscheduler-shared-local:/opt/soft
      - dolphinscheduler-resource-local:/dolphinscheduler
    networks:
      - default