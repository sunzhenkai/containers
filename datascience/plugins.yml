networks:
  datascience:
    external: true
    name: datascience
services:
  portainer:
    image: portainer/portainer-ce:2.21.2
    restart: always
    networks:
      - datascience
    ports:
      - 8262:8000
      - 8263:9000
      - 8264:9443
    volumes:
      - portainer:/data
      - /var/run/docker.sock:/var/run/docker.sock
  gitlab-web:
    image: "gitlab/gitlab-ce:latest"
    restart: always
    container_name: datascience-lab
    hostname: datascience-gitlab
    environment:
      GITLAB_OMNIBUS_CONFIG: |
        external_url 'http://datascience:8929'
        gitlab_rails['gitlab_shell_ssh_port'] = 2224
        # Add any other gitlab.rb configuration here, each on its own line
    ports:
      - "8929:8929"
      - "2224:22"
    volumes:
      - "gitlab-config:/etc/gitlab"
      - "gitlab-log:/var/log/gitlab"
      - "gitlab-data:/var/opt/gitlab"
    shm_size: "256m"
    networks:
      - datascience
  gitlab-runner:
    image: gitlab/gitlab-runner:alpine
    restart: always
    depends_on:
      - gitlab-web
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - "gitlab-runner:/etc/gitlab-runner"
    networks:
      - datascience
  scylladb-meta:
    image: scylladb/scylla:5.2.6
    container_name: datascience-scylladb
    hostname: datascience-scylladb
    restart: always
    command: --seeds=scylla-meta --smp 1 --memory 750M --overprovisioned 1 --api-address 0.0.0.0
    networks:
      - datascience
    ports:
      - "7000:7000"
      - "7001:7001"
      - "9042:9042"
      - "9160:9160"
      - "10000:10000"
  scylladb-node:
    image: scylladb/scylla:5.2.6
    restart: always
    command: --seeds=scylla-meta --smp 1 --memory 750M --overprovisioned 1 --api-address 0.0.0.0
    networks:
      - datascience
    deploy:
      mode: replicated
      replicas: 2
    depends_on:
      - scylladb-meta
  # dolphinscheduler
  dolphinscheduler-schema-initializer:
    image: apache/dolphinscheduler-tools:latest
    profiles: ["init"]
    command: [tools/bin/upgrade-schema.sh]
    env_file:
      - ./config/dolphinscheduler/env
    depends_on:
      postgresql:
        condition: service_healthy
    volumes:
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
      - dolphinscheduler-shared-local:/opt/soft
      - dolphinscheduler-resource-local:/dolphinscheduler
    networks:
      - datascience
  dolphinscheduler-api:
    image: apache/dolphinscheduler-api:latest
    env_file:
      - ./config/dolphinscheduler/env
    ports:
      - "12345:12345"
      - "25333:25333"
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "http://localhost:12345/dolphinscheduler/actuator/health",
        ]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
      - dolphinscheduler-shared-local:/opt/soft
      - dolphinscheduler-resource-local:/dolphinscheduler
    networks:
      - datascience
  dolphinscheduler-alert:
    image: apache/dolphinscheduler-alert-server:latest
    env_file:
      - ./config/dolphinscheduler/env
    healthcheck:
      test: ["CMD", "curl", "http://localhost:50053/actuator/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
    networks:
      - datascience
  dolphinscheduler-master:
    image: apache/dolphinscheduler-master:latest
    container_name: datascience-dolphinscheduler
    hostname: datascience-dolphinscheduler
    env_file:
      - ./config/dolphinscheduler/env
    healthcheck:
      test: ["CMD", "curl", "http://localhost:5679/actuator/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
      - dolphinscheduler-shared-local:/opt/soft
    networks:
      - datascience
  dolphinscheduler-worker:
    image: apache/dolphinscheduler-worker:latest
    env_file:
      - ./config/dolphinscheduler/env
    healthcheck:
      test: ["CMD", "curl", "http://localhost:1235/actuator/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
      - dolphinscheduler-worker-data:/tmp/dolphinscheduler
      - dolphinscheduler-logs:/opt/dolphinscheduler/logs
      - dolphinscheduler-shared-local:/opt/soft
      - dolphinscheduler-resource-local:/dolphinscheduler
    networks:
      - datascience
  development:
    image: sunzhenkai/development:0.0.3
    container_name: datascience-dev
    hostname: datascience-dev
    command: ["/sbin/init"]
    restart: always
    privileged: true
    networks:
      - datascience
    ports:
      - 2025:22
      - 8285:8085
    volumes:
      - data:/data
  development-gpu:
    image: sunzhenkai/development:0.0.3
    profiles: [gpu]
    container_name: datascience-dev-gpu
    hostname: datascience-dev-gpu
    command: ["/sbin/init"]
    restart: always
    privileged: true
    networks:
      - datascience
    ports:
      - 2026:22
      - 8288:8085
    volumes:
      - data:/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  spark:
    image: docker.io/bitnami/spark:3.4
    container_name: datascience-spark
    hostname: datascience-spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - 8286:8080
      - 8277:7077
    networks:
      - datascience
  spark-worker:
    image: docker.io/bitnami/spark:3.4
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://datascience-spark:7077
      - SPARK_WORKER_MEMORY=30G
      - SPARK_WORKER_CORES=15
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    networks:
      - datascience
    deploy:
      mode: replicated
      replicas: 2
    depends_on:
      - spark
  zeppelin:
    image: apache/zeppelin:0.10.1
    container_name: datascience-zeppelin
    hostname: datascience-zeppelin
    environment:
      - ZEPPELIN_LOG_DIR='/data/zeeplin/logs'
      - ZEPPELIN_NOTEBOOK_DIR='/data/zeeplin/notebook'
    ports:
      - 8280:8080
    networks:
      - datascience
    volumes:
      - data:/data
  flink-jobmanager:
    image: docker.io/bitnami/flink:1
    container_name: datascience-flink
    hostname: datascience-flink
    ports:
      - 8223:6123
      - 8220:8081
    environment:
      - FLINK_MODE=jobmanager
      - FLINK_CFG_REST_BIND__ADDRESS=0.0.0.0
    networks:
      - datascience
    volumes:
      - ./config/flink/master:/bitnami/flink/conf/master
      - ./config/flink/flink-conf.yaml:/bitnami/flink/conf/flink-conf.yaml
      - ./config/flink/log4j-console.properties:/bitnami/flink/conf/log4j-console.properties
      - ./config/flink/log4j-session.properties:/bitnami/flink/conf/log4j-session.properties
      - ./config/flink/log4j.properties:/bitnami/flink/conf/log4j.properties
      - ./config/flink/logback-console.xml:/bitnami/flink/conf/logback-console.xml
      - ./config/flink/logback-session.xml:/bitnami/flink/conf/logback-session.xml
      - ./config/flink/logback.xml:/bitnami/flink/conf/logback.xml
      - ./config/flink/workers:/bitnami/flink/conf/workers
      - ./config/flink/zoo.cfg:/bitnami/flink/conf/zoo.cfg
  flink-taskmanager:
    image: docker.io/bitnami/flink:1
    user: root
    ports:
      - 8221:6121
      - 8222:6122
    environment:
      - FLINK_MODE=taskmanager
      - FLINK_JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    networks:
      - datascience
    volumes:
      - ./config/flink/master:/bitnami/flink/conf/master
      - ./config/flink/flink-conf.yaml:/bitnami/flink/conf/flink-conf.yaml
      - ./config/flink/log4j-console.properties:/bitnami/flink/conf/log4j-console.properties
      - ./config/flink/log4j-session.properties:/bitnami/flink/conf/log4j-session.properties
      - ./config/flink/log4j.properties:/bitnami/flink/conf/log4j.properties
      - ./config/flink/logback-console.xml:/bitnami/flink/conf/logback-console.xml
      - ./config/flink/logback-session.xml:/bitnami/flink/conf/logback-session.xml
      - ./config/flink/logback.xml:/bitnami/flink/conf/logback.xml
      - ./config/flink/workers:/bitnami/flink/conf/workers
      - ./config/flink/zoo.cfg:/bitnami/flink/conf/zoo.cfg
  kafka:
    container_name: datascience-kafka
    hostname: datascience-kafka
    image: docker.io/bitnami/kafka:3.5
    ports:
      - 9092:9092
    volumes:
      - "kafka:/bitnami"
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    networks:
      - datascience
  clickhouse:
    image: docker.io/bitnami/clickhouse:23
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - "8233:8123"
    volumes:
      - clickhouse:/bitnami/clickhouse
    networks:
      - datascience
  postgresql:
    user: root
    image: docker.io/bitnami/postgresql:15
    volumes:
      - "postgresql:/bitnami/postgresql"
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "bash", "-c", "cat < /dev/null > /dev/tcp/127.0.0.1/5432"]
      interval: 5s
      timeout: 60s
      retries: 120
    networks:
      - datascience
  redis:
    image: docker.io/bitnami/redis:7.0
    container_name: datascience-redis
    hostname: datascience-redis
    volumes:
      - "redis:/bitnami"
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - "6379:6379"
    networks:
      - datascience
  airflow-scheduler:
    image: docker.io/bitnami/airflow-scheduler:2
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    networks:
      - datascience
  airflow-worker:
    image: docker.io/bitnami/airflow-worker:2
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    networks:
      - datascience
  airflow:
    image: docker.io/bitnami/airflow:2
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_PASSWORD=bitnami123
      - AIRFLOW_USERNAME=user
      - AIRFLOW_EMAIL=user@example.com
    ports:
      - "8208:8080"
    networks:
      - datascience
  prometheus:
    image: docker.io/bitnami/prometheus:2
    ports:
      - "8290:9090"
    networks:
      - datascience
  mongodb:
    image: docker.io/bitnami/mongodb:6.0
    container_name: datascience-mongodb
    hostname: datascience-mongodb
    ports:
      - "27017:27017"
    volumes:
      - "mongodb:/bitnami/mongodb"
    networks:
      - datascience
  grafana:
    image: docker.io/bitnami/grafana:10
    container_name: datascience-grafana
    hostname: datascience-grafana
    ports:
      - "3000:3000"
    environment:
      - "GF_SECURITY_ADMIN_PASSWORD=bitnami"
    volumes:
      - grafana:/opt/bitnami/grafana/data
    networks:
      - datascience
  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    container_name: datascience-zookeeper
    hostname: datascience-zookeeper
    user: root
    ports:
      - "2181:2181"
    volumes:
      - "zookeeper:/bitnami/zookeeper"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - datascience
    healthcheck:
      test: ["CMD", "bash", "-c", "cat < /dev/null > /dev/tcp/127.0.0.1/2181"]
      interval: 5s
      timeout: 60s
      retries: 120

volumes:
  data:
  portainer:
  gitlab-config:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/gitlab/config
  gitlab-log:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/gitlab/log
  gitlab-data:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/gitlab/data
  gitlab-runner:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/docker/datascience/data/gitlab/runner
  dolphinscheduler-worker-data:
  dolphinscheduler-logs:
  dolphinscheduler-shared-local:
  dolphinscheduler-resource-local:
  kafka:
  clickhouse:
  zookeeper:
  postgresql:
  redis:
  mongodb:
  grafana:
  flink: