networks:
  datascience:
    driver: bridge
    name: datascience
    ipam:
      config:
        - subnet: "172.50.0.0/24"
          gateway: "172.50.0.1"
services:
  hadoop-namenode:
    image: apache/hadoop:3.3.6
    hostname: namenode
    command: ["hdfs", "namenode"]
    restart: always
    container_name: hadoop-namenode
    ports:
      - 9870:9870
      - 8020:8020
      - 8020:8020/udp
    env_file:
      - ./config/hadoop/hadoop.env
    volumes:
      - hadoop:/data
      # - ./hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    environment:
      ENSURE_NAMENODE_DIR: "/data/dfs/name"
      CLUSTER_NAME: prod
    networks:
      - datascience
  hadoop-datanode:
    image: apache/hadoop:3.3.6
    command: ["hdfs", "datanode"]
    restart: always
    env_file:
      - ./config/hadoop/hadoop.env
    networks:
      - datascience
    volumes:
      - hadoop:/data
  hadoop-resourcemanager:
    image: apache/hadoop:3.3.6
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    restart: always
    depends_on:
      - hadoop-namenode
      - hadoop-datanode
    ports:
      - 8088:8088
    env_file:
      - ./config/hadoop/hadoop.env
    networks:
      - datascience
    volumes:
      - hadoop:/data
  hadoop-nodemanager:
    image: apache/hadoop:3.3.6
    command: ["yarn", "nodemanager"]
    restart: always
    depends_on:
      - hadoop-namenode
      - hadoop-datanode
      - hadoop-resourcemanager
    env_file:
      - ./config/hadoop/hadoop.env
    networks:
      - datascience
    volumes:
      - hadoop:/data
  hadoop-historyserver:
    image: apache/hadoop:3.3.6
    command: ["yarn", "historyserver"]
    restart: always
    hostname: historyserver
    env_file:
      - ./config/hadoop/hadoop.env
    depends_on:
      - hadoop-namenode
      - hadoop-datanode
      - hadoop-resourcemanager
      - hadoop-nodemanager
    networks:
      - datascience
    volumes:
      - hadoop:/data
  development:
    image: sunzhenkai/development:0.0.3
    container_name: datascience-dev
    hostname: datascience-dev
    command: ["/sbin/init"]
    restart: always
    privileged: true
    networks:
      - datascience
    ports:
      - 2025:22
      - 8285:8085
    volumes:
      - data:/data
  development-gpu:
    image: sunzhenkai/development:0.0.3
    profiles: [gpu]
    container_name: datascience-dev-gpu
    hostname: datascience-dev-gpu
    command: ["/sbin/init"]
    restart: always
    privileged: true
    networks:
      - datascience
    ports:
      - 2026:22
      - 8288:8085
    volumes:
      - data:/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  spark:
    image: docker.io/bitnami/spark:3.4
    container_name: datascience-spark
    hostname: datascience-spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - 8286:8080
      - 8277:7077
    networks:
      - datascience
  spark-worker:
    image: docker.io/bitnami/spark:3.4
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=30G
      - SPARK_WORKER_CORES=15
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    networks:
      - datascience
    deploy:
      mode: replicated
      replicas: 2
    depends_on:
      - spark
  zeppelin:
    image: apache/zeppelin:0.10.1
    container_name: datascience-zeppelin
    hostname: datascience-zeppelin
    environment:
      - ZEPPELIN_LOG_DIR='/data/zeeplin/logs'
      - ZEPPELIN_NOTEBOOK_DIR='/data/zeeplin/notebook'
    ports:
      - 8280:8080
    networks:
      - datascience
    volumes:
      - data:/data
  flink-jobmanager:
    image: docker.io/bitnami/flink:1
    container_name: datascience-flink
    hostname: datascience-flink
    ports:
      - 8223:6123
      - 8220:8081
    environment:
      - FLINK_MODE=jobmanager
      - FLINK_CFG_REST_BIND__ADDRESS=0.0.0.0
    networks:
      - datascience
    volumes:
      - ./config/flink/master:/bitnami/flink/conf/master
      - ./config/flink/flink-conf.yaml:/bitnami/flink/conf/flink-conf.yaml
      - ./config/flink/log4j-console.properties:/bitnami/flink/conf/log4j-console.properties
      - ./config/flink/log4j-session.properties:/bitnami/flink/conf/log4j-session.properties
      - ./config/flink/log4j.properties:/bitnami/flink/conf/log4j.properties
      - ./config/flink/logback-console.xml:/bitnami/flink/conf/logback-console.xml
      - ./config/flink/logback-session.xml:/bitnami/flink/conf/logback-session.xml
      - ./config/flink/logback.xml:/bitnami/flink/conf/logback.xml
      - ./config/flink/workers:/bitnami/flink/conf/workers
      - ./config/flink/zoo.cfg:/bitnami/flink/conf/zoo.cfg
  flink-taskmanager:
    image: docker.io/bitnami/flink:1
    user: root
    ports:
      - 8221:6121
      - 8222:6122
    environment:
      - FLINK_MODE=taskmanager
      - FLINK_JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    networks:
      - datascience
    volumes:
      - ./config/flink/master:/bitnami/flink/conf/master
      - ./config/flink/flink-conf.yaml:/bitnami/flink/conf/flink-conf.yaml
      - ./config/flink/log4j-console.properties:/bitnami/flink/conf/log4j-console.properties
      - ./config/flink/log4j-session.properties:/bitnami/flink/conf/log4j-session.properties
      - ./config/flink/log4j.properties:/bitnami/flink/conf/log4j.properties
      - ./config/flink/logback-console.xml:/bitnami/flink/conf/logback-console.xml
      - ./config/flink/logback-session.xml:/bitnami/flink/conf/logback-session.xml
      - ./config/flink/logback.xml:/bitnami/flink/conf/logback.xml
      - ./config/flink/workers:/bitnami/flink/conf/workers
      - ./config/flink/zoo.cfg:/bitnami/flink/conf/zoo.cfg
  kafka:
    container_name: datascience-kafka
    hostname: datascience-kafka
    image: docker.io/bitnami/kafka:3.5
    ports:
      - 9092:9092
    volumes:
      - "kafka:/bitnami"
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    networks:
      - datascience
  consul:
    image: docker.io/bitnami/consul:1
    container_name: datascience-consul
    hostname: datascience-consul
    user: root
    volumes:
      #- consul:/bitnami/consul
      - ./config/consul/standalone:/opt/bitnami/consul/consul.json
    ports:
      - "8300:8300"
      - "8301:8301"
      - "8301:8301/udp"
      - "8500:8500"
      - "8600:8600"
      - "8600:8600/udp"
    environment:
      - CONSUL_DISABLE_KEYRING_FILE=true
      - CONSUL_BIND_ADDR=127.0.0.1
    networks:
      - datascience
  clickhouse:
    image: docker.io/bitnami/clickhouse:23
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - "8233:8123"
    volumes:
      - clickhouse:/bitnami/clickhouse
    networks:
      - datascience
  postgresql:
    user: root
    image: docker.io/bitnami/postgresql:15
    volumes:
      - "postgresql:/bitnami/postgresql"
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "bash", "-c", "cat < /dev/null > /dev/tcp/127.0.0.1/5432"]
      interval: 5s
      timeout: 60s
      retries: 120
    networks:
      - datascience
  redis:
    image: docker.io/bitnami/redis:7.0
    container_name: datascience-redis
    hostname: datascience-redis
    volumes:
      - "redis:/bitnami"
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - "6379:6379"
    networks:
      - datascience
  airflow-scheduler:
    image: docker.io/bitnami/airflow-scheduler:2
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    networks:
      - datascience
  airflow-worker:
    image: docker.io/bitnami/airflow-worker:2
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    networks:
      - datascience
  airflow:
    image: docker.io/bitnami/airflow:2
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_PASSWORD=bitnami123
      - AIRFLOW_USERNAME=user
      - AIRFLOW_EMAIL=user@example.com
    ports:
      - "8208:8080"
    networks:
      - datascience
  prometheus:
    image: docker.io/bitnami/prometheus:2
    ports:
      - "8290:9090"
    networks:
      - datascience
  mongodb:
    image: docker.io/bitnami/mongodb:6.0
    container_name: datascience-mongodb
    hostname: datascience-mongodb
    ports:
      - "27017:27017"
    volumes:
      - "mongodb:/bitnami/mongodb"
    networks:
      - datascience
  mariadb:
    image: docker.io/bitnami/mariadb:10.9.7
    container_name: datascience-mariadb
    hostname: datascience-mariadb
    ports:
      - "3306:3306"
    volumes:
      - "mariadb:/bitnami/mariadb"
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    healthcheck:
      test: ["CMD", "/opt/bitnami/scripts/mariadb/healthcheck.sh"]
      interval: 15s
      timeout: 5s
      retries: 6
    networks:
      - datascience
  phpmyadmin:
    image: docker.io/bitnami/phpmyadmin:5
    container_name: datascience-phpmyadmin
    hostname: datascience-phpmyadmin
    ports:
      - "8283:8080"
      - "8243:8443"
    depends_on:
      - mariadb
    networks:
      - datascience
  grafana:
    image: docker.io/bitnami/grafana:10
    container_name: datascience-grafana
    hostname: datascience-grafana
    ports:
      - "3000:3000"
    environment:
      - "GF_SECURITY_ADMIN_PASSWORD=bitnami"
    volumes:
      - grafana:/opt/bitnami/grafana/data
    networks:
      - datascience
  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    container_name: datascience-zookeeper
    hostname: datascience-zookeeper
    user: root
    ports:
      - "2181:2181"
    volumes:
      - "zookeeper:/bitnami/zookeeper"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - datascience
    healthcheck:
      test: ["CMD", "bash", "-c", "cat < /dev/null > /dev/tcp/127.0.0.1/2181"]
      interval: 5s
      timeout: 60s
      retries: 120
  azkaban-executor-server:
    image: sunzhenkai/azkaban-executor-server:latest
    restart: always
    hostname: azkaban-executor-server
    environment:
      AZKABAN_MYSQL_HOST: mariadb
    networks:
      - datascience
    depends_on:
      mariadb:
        condition: service_healthy
  azkaban-web-server:
    image: sunzhenkai/azkaban-web-server:latest
    container_name: datascience-azkaban
    hostname: azkaban-web-server
    restart: always
    environment:
      AZKABAN_MYSQL_HOST: mariadb
    networks:
      - datascience
    ports:
      - 8261:8081
    depends_on:
      azkaban-executor-server:
        condition: service_healthy
      mariadb:
        condition: service_healthy

volumes:
  data:
  kafka:
  hadoop:
  mariadb:
  clickhouse:
  consul:
  zookeeper:
  postgresql:
  redis:
  mongodb:
  grafana:
  flink: