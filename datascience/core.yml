networks:
  datascience:
    driver: bridge
    name: datascience
    ipam:
      config:
        - subnet: "172.50.0.0/24"
          gateway: "172.50.0.1"

x-hadoop-common-config:
  &hadoop-common-config
  image: apache/hadoop:3.4.1
  volumes:
    - hadoop:/opt/hadoop
  env_file:
    - ./config/hadoop/config
x-flink-jobmanager:
  &flink-jobmanager-common-config
  image: docker.io/bitnami/flink:1
  networks:
    - datascience
  volumes:
    - ./config/flink/master:/bitnami/flink/conf/master
    - ./config/flink/flink-conf.yaml:/bitnami/flink/conf/flink-conf.yaml
    - ./config/flink/log4j-console.properties:/bitnami/flink/conf/log4j-console.properties
    - ./config/flink/log4j-session.properties:/bitnami/flink/conf/log4j-session.properties
    - ./config/flink/log4j.properties:/bitnami/flink/conf/log4j.properties
    - ./config/flink/logback-console.xml:/bitnami/flink/conf/logback-console.xml
    - ./config/flink/logback-session.xml:/bitnami/flink/conf/logback-session.xml
    - ./config/flink/logback.xml:/bitnami/flink/conf/logback.xml
    - ./config/flink/workers:/bitnami/flink/conf/workers
    - ./config/flink/zoo.cfg:/bitnami/flink/conf/zoo.cfg

services:
  # hadoop
  namenode:
    <<: *hadoop-common-config
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
      - 8020:8020
      - 8020:8020/udp
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    networks:
      - datascience
  datanode:
    <<: *hadoop-common-config
    hostname: datanode
    command: ["hdfs", "datanode"]
    networks:
      - datascience
  resourcemanager:
    <<: *hadoop-common-config
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
      - 8088:8088
    networks:
      - datascience
  nodemanager:
    <<: *hadoop-common-config
    hostname: nodemanager
    command: ["yarn", "nodemanager"]
    networks:
      - datascience  # azkaban
  azkaban-executor-server:
    image: sunzhenkai/azkaban-executor-server:latest
    restart: always
    hostname: azkaban-executor-server
    environment:
      AZKABAN_MYSQL_HOST: mariadb
      AZKABAN_MYSQL_USERNAME: azkaban
      AZKABAN_MYSQL_PASSWORD: azkaban
    networks:
      - datascience
    depends_on:
      mariadb:
        condition: service_healthy
  azkaban-web-server:
    image: sunzhenkai/azkaban-web-server:latest
    container_name: datascience-azkaban
    hostname: azkaban-web-server
    restart: always
    environment:
      AZKABAN_MYSQL_HOST: mariadb
      AZKABAN_MYSQL_USERNAME: azkaban
      AZKABAN_MYSQL_PASSWORD: azkaban
    networks:
      - datascience
    ports:
      - 8261:8081
    depends_on:
      azkaban-executor-server:
        condition: service_healthy
      mariadb:
        condition: service_healthy
  kafka:
    container_name: datascience-kafka
    hostname: datascience-kafka
    image: docker.io/bitnami/kafka:3.5
    ports:
      - 9092:9092
    volumes:
      - "kafka:/bitnami"
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    networks:
      - datascience
  spark:
    image: docker.io/bitnami/spark:3.4
    container_name: datascience-spark
    hostname: datascience-spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - 8286:8080
      - 8277:7077
    networks:
      - datascience
  spark-worker:
    image: docker.io/bitnami/spark:3.4
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://datascience-spark:7077
      - SPARK_WORKER_MEMORY=30G
      - SPARK_WORKER_CORES=15
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    networks:
      - datascience
    deploy:
      mode: replicated
      replicas: 2
    depends_on:
      - spark
  zeppelin:
    image: apache/zeppelin:0.10.1
    container_name: datascience-zeppelin
    hostname: datascience-zeppelin
    environment:
      - ZEPPELIN_LOG_DIR='/data/zeeplin/logs'
      - ZEPPELIN_NOTEBOOK_DIR='/data/zeeplin/notebook'
    ports:
      - 8280:8080
    networks:
      - datascience
    volumes:
      - data:/data
  flink-jobmanager:
    <<: *flink-jobmanager-common-config
    container_name: datascience-flink
    hostname: datascience-flink
    ports:
      - 8223:6123
      - 8220:8081
    environment:
      - FLINK_MODE=jobmanager
      - FLINK_CFG_REST_BIND__ADDRESS=0.0.0.0
    networks:
      - datascience
  flink-taskmanager:
    <<: *flink-jobmanager-common-config
    user: root
    ports:
      - 8221:6121
      - 8222:6122
    environment:
      - FLINK_MODE=taskmanager
      - FLINK_JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    networks:
      - datascience
  # consul
  consul:
    image: docker.io/bitnami/consul:1
    container_name: datascience-consul
    hostname: datascience-consul
    user: root
    volumes:
      - consul:/bitnami/consul
      - ./config/consul/standalone:/opt/bitnami/consul/consul.json
    ports:
      - "8300:8300"
      - "8301:8301"
      - "8301:8301/udp"
      - "8500:8500"
      - "8600:8600"
      - "8600:8600/udp"
    environment:
      - CONSUL_DISABLE_KEYRING_FILE=true
      - CONSUL_BIND_ADDR=127.0.0.1
    networks:
      - datascience
  # database
  mariadb:
    image: docker.io/bitnami/mariadb:10.9.7
    container_name: datascience-mariadb
    hostname: datascience-mariadb
    ports:
      - "3306:3306"
    volumes:
      - "mariadb:/bitnami/mariadb"
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    healthcheck:
      test: ["CMD", "/opt/bitnami/scripts/mariadb/healthcheck.sh"]
      interval: 15s
      timeout: 5s
      retries: 6
    networks:
      - datascience
  redis:
    image: docker.io/bitnami/redis:7.0
    container_name: datascience-redis
    hostname: datascience-redis
    volumes:
      - "redis:/bitnami"
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - "6379:6379"
    networks:
      - datascience

  phpmyadmin:
    image: docker.io/bitnami/phpmyadmin:5
    container_name: datascience-phpmyadmin
    hostname: datascience-phpmyadmin
    ports:
      - "8283:8080"
      - "8243:8443"
    depends_on:
      - mariadb
    networks:
      - datascience
volumes:
  data:
  hadoop:
  consul:
  mariadb:
  redis:
  kafka:
